{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MapReduce\n",
    "\n",
    "For this exercise we are going to use MapReduce in local mode, i.e. we won't be running anything on the cluster!\n",
    " \n",
    "## 3.1. Use the commands `head`, `cat`, `uniq`, `wc`, `sort`, `find`, `xargs`, `awk` to evaluate the NASA log file:\n",
    "\n",
    "* Data File:  <https://github.com/scalable-infrastructure/exercise-2018/blob/master/data/nasa/NASA_access_log_Jul95.gz>\n",
    "* Which page was called the most?\n",
    "* What was the most frequent return code?\n",
    "* How many errors occurred? What is the percentage of errors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hpc/pn69si/mnmda001/git/exercise-2018/03_MapReduce\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!gzip -k -d -f  ../data/nasa/NASA_access_log_Jul95.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA_access_log_Jul95  NASA_access_log_Jul95.gz\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/nasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1701534 200\n",
      "  46573 302\n",
      " 132627 304\n",
      "      5 400\n",
      "     54 403\n",
      "  10845 404\n",
      "     62 500\n",
      "     14 501\n",
      "      1 alyssa.p\n",
      "CPU times: user 923 ms, sys: 220 ms, total: 1.14 s\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!cat ../data/nasa/NASA_access_log_Jul95 | awk  '{print $(NF-1)}'| sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = !cat ../data/nasa/NASA_access_log_Jul95 | awk  '{print $(NF-1)}'| sort | uniq -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>HTTP RC</th>\n",
       "      <th>Counts_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1701534</td>\n",
       "      <td>200</td>\n",
       "      <td>89.946636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46573</td>\n",
       "      <td>302</td>\n",
       "      <td>2.461946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132627</td>\n",
       "      <td>304</td>\n",
       "      <td>7.010940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>0.000264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>403</td>\n",
       "      <td>0.002855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10845</td>\n",
       "      <td>404</td>\n",
       "      <td>0.573289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>62</td>\n",
       "      <td>500</td>\n",
       "      <td>0.003277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>501</td>\n",
       "      <td>0.000740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>alyssa.p</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Count   HTTP RC  Counts_pct\n",
       "0  1701534       200   89.946636\n",
       "1    46573       302    2.461946\n",
       "2   132627       304    7.010940\n",
       "3        5       400    0.000264\n",
       "4       54       403    0.002855\n",
       "5    10845       404    0.573289\n",
       "6       62       500    0.003277\n",
       "7       14       501    0.000740\n",
       "8        1  alyssa.p    0.000053"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame.from_records([i.split() for i in data], columns=[\"Count\", \"HTTP RC\"])\n",
    "df[\"Count\"]=pd.to_numeric(df[\"Count\"], errors='coerce')\n",
    "df[\"Counts_pct\"]=(df[\"Count\"]/df[\"Count\"].sum()*100) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Implement a Python version of this Unix Shell script using this script as template! Run the Python script inside an Hadoop Streaming job.\n",
    "\n",
    "Template: <https://github.com/scalable-infrastructure/scalable-infrastructure.github.io/blob/master/src/map_reduce.py>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HADOOP_HOME\"]=\"/naslx/projects/pn69si/mnmda001/software/hadoop-2.7.5\"\n",
    "os.environ[\"PATH\"]=\"/naslx/projects/pn69si/mnmda001/software/hadoop-2.7.5/bin:\"+os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: $HADOOP_PREFIX/bin/hadoop jar hadoop-streaming.jar [options]\n",
      "Options:\n",
      "  -input          <path> DFS input file(s) for the Map step.\n",
      "  -output         <path> DFS output directory for the Reduce step.\n",
      "  -mapper         <cmd|JavaClassName> Optional. Command to be run as mapper.\n",
      "  -combiner       <cmd|JavaClassName> Optional. Command to be run as combiner.\n",
      "  -reducer        <cmd|JavaClassName> Optional. Command to be run as reducer.\n",
      "  -file           <file> Optional. File/dir to be shipped in the Job jar file.\n",
      "                  Deprecated. Use generic option \"-files\" instead.\n",
      "  -inputformat    <TextInputFormat(default)|SequenceFileAsTextInputFormat|JavaClassName>\n",
      "                  Optional. The input format class.\n",
      "  -outputformat   <TextOutputFormat(default)|JavaClassName>\n",
      "                  Optional. The output format class.\n",
      "  -partitioner    <JavaClassName>  Optional. The partitioner class.\n",
      "  -numReduceTasks <num> Optional. Number of reduce tasks.\n",
      "  -inputreader    <spec> Optional. Input recordreader spec.\n",
      "  -cmdenv         <n>=<v> Optional. Pass env.var to streaming commands.\n",
      "  -mapdebug       <cmd> Optional. To run this script when a map task fails.\n",
      "  -reducedebug    <cmd> Optional. To run this script when a reduce task fails.\n",
      "  -io             <identifier> Optional. Format to use for input to and output\n",
      "                  from mapper/reducer commands\n",
      "  -lazyOutput     Optional. Lazily create Output.\n",
      "  -background     Optional. Submit the job and don't wait till it completes.\n",
      "  -verbose        Optional. Print verbose output.\n",
      "  -info           Optional. Print detailed usage.\n",
      "  -help           Optional. Print help message.\n",
      "\n",
      "Generic options supported are\n",
      "-conf <configuration file>     specify an application configuration file\n",
      "-D <property=value>            use value for given property\n",
      "-fs <local|namenode:port>      specify a namenode\n",
      "-jt <local|resourcemanager:port>    specify a ResourceManager\n",
      "-files <comma separated list of files>    specify comma separated files to be copied to the map reduce cluster\n",
      "-libjars <comma separated list of jars>    specify comma separated jar files to include in the classpath.\n",
      "-archives <comma separated list of archives>    specify comma separated archives to be unarchived on the compute machines.\n",
      "\n",
      "The general command line syntax is\n",
      "bin/hadoop command [genericOptions] [commandOptions]\n",
      "\n",
      "\n",
      "Usage tips:\n",
      "In -input: globbing on <path> is supported and can have multiple -input\n",
      "\n",
      "Default Map input format: a line is a record in UTF-8 the key part ends at first\n",
      "  TAB, the rest of the line is the value\n",
      "\n",
      "To pass a Custom input format:\n",
      "  -inputformat package.MyInputFormat\n",
      "\n",
      "Similarly, to pass a custom output format:\n",
      "  -outputformat package.MyOutputFormat\n",
      "\n",
      "The files with extensions .class and .jar/.zip, specified for the -file\n",
      "  argument[s], end up in \"classes\" and \"lib\" directories respectively inside\n",
      "  the working directory when the mapper and reducer are run. All other files\n",
      "  specified for the -file argument[s] end up in the working directory when the\n",
      "  mapper and reducer are run. The location of this working directory is\n",
      "  unspecified.\n",
      "\n",
      "To set the number of reduce tasks (num. of output files) as, say 10:\n",
      "  Use -numReduceTasks 10\n",
      "To skip the sort/combine/shuffle/sort/reduce step:\n",
      "  Use -numReduceTasks 0\n",
      "  Map output then becomes a 'side-effect output' rather than a reduce input.\n",
      "  This speeds up processing. This also feels more like \"in-place\" processing\n",
      "  because the input filename and the map input order are preserved.\n",
      "  This is equivalent to -reducer NONE\n",
      "\n",
      "To speed up the last maps:\n",
      "  -D mapreduce.map.speculative=true\n",
      "To speed up the last reduces:\n",
      "  -D mapreduce.reduce.speculative=true\n",
      "To name the job (appears in the JobTracker Web UI):\n",
      "  -D mapreduce.job.name='My Job'\n",
      "To change the local temp directory:\n",
      "  -D dfs.data.dir=/tmp/dfs\n",
      "  -D stream.tmpdir=/tmp/streaming\n",
      "Additional local temp directories with -jt local:\n",
      "  -D mapreduce.cluster.local.dir=/tmp/local\n",
      "  -D mapreduce.jobtracker.system.dir=/tmp/system\n",
      "  -D mapreduce.cluster.temp.dir=/tmp/temp\n",
      "To treat tasks with non-zero exit status as SUCCEDED:\n",
      "  -D stream.non.zero.exit.is.failure=false\n",
      "Use a custom hadoop streaming build along with standard hadoop install:\n",
      "  $HADOOP_PREFIX/bin/hadoop jar /path/my-hadoop-streaming.jar [...]\\\n",
      "    [...] -D stream.shipped.hadoopstreaming=/path/my-hadoop-streaming.jar\n",
      "For more details about jobconf parameters see:\n",
      "  http://wiki.apache.org/hadoop/JobConfFile\n",
      "To set an environement variable in a streaming command:\n",
      "   -cmdenv EXAMPLE_DIR=/home/example/dictionaries/\n",
      "\n",
      "Shortcut:\n",
      "   setenv HSTREAMING \"$HADOOP_PREFIX/bin/hadoop jar hadoop-streaming.jar\"\n",
      "\n",
      "Example: $HSTREAMING -mapper \"/usr/local/bin/perl5 filter.pl\"\n",
      "           -file /local/filter.pl -input \"/logs/0604*/*\" [...]\n",
      "  Ships a script, invokes the non-shipped perl interpreter. Shipped files go to\n",
      "  the working directory so filter.pl is found by perl. Input files are all the\n",
      "  daily logs for days in month 2006-04\n"
     ]
    }
   ],
   "source": [
    "!hadoop jar ${HADOOP_HOME}/share/hadoop/tools/lib/hadoop-streaming-2.7.5.jar -info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/04/05 09:15:18 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "packageJobJar: [/home/hpc/pn69si/mnmda001/git/exercise-2018/03_MapReduce/map_reduce_solution.py] [] /tmp/streamjob7563165842408199726.jar tmpDir=null\n",
      "18/04/05 09:15:20 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "18/04/05 09:15:20 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "18/04/05 09:15:20 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "18/04/05 09:15:21 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "18/04/05 09:15:21 INFO mapreduce.JobSubmitter: number of splits:7\n",
      "18/04/05 09:15:22 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local810022510_0001\n",
      "18/04/05 09:15:24 INFO mapred.LocalDistributedCacheManager: Localized file:/home/hpc/pn69si/mnmda001/git/exercise-2018/03_MapReduce/map_reduce_solution.py as file:/naslx/projects/pn69si/mnmda001/software/hadoop-2.7.5/tmp/1522912523699/map_reduce_solution.py\n",
      "18/04/05 09:15:24 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "18/04/05 09:15:24 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "18/04/05 09:15:24 INFO mapreduce.Job: Running job: job_local810022510_0001\n",
      "18/04/05 09:15:24 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
      "18/04/05 09:15:24 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/04/05 09:15:24 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "18/04/05 09:15:24 INFO mapred.LocalJobRunner: Starting task: attempt_local810022510_0001_m_000000_0\n",
      "18/04/05 09:15:24 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/04/05 09:15:24 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/04/05 09:15:24 INFO mapred.MapTask: Processing split: file:/home/hpc/pn69si/mnmda001/git/exercise-2018/data/nasa/NASA_access_log_Jul95:0+33554432\n",
      "18/04/05 09:15:24 INFO mapred.MapTask: numReduceTasks: 1\n",
      "18/04/05 09:15:24 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "18/04/05 09:15:24 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "18/04/05 09:15:24 INFO mapred.MapTask: soft limit at 83886080\n",
      "18/04/05 09:15:24 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "18/04/05 09:15:24 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "18/04/05 09:15:24 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "18/04/05 09:15:24 INFO streaming.PipeMapRed: PipeMapRed exec [/home/hpc/pn69si/mnmda001/git/exercise-2018/03_MapReduce/./map_reduce_solution.py, map]\n",
      "18/04/05 09:15:24 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
      "18/04/05 09:15:24 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
      "18/04/05 09:15:24 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "18/04/05 09:15:24 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "18/04/05 09:15:24 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "18/04/05 09:15:24 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
      "18/04/05 09:15:24 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
      "18/04/05 09:15:24 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "18/04/05 09:15:24 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
      "18/04/05 09:15:24 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "18/04/05 09:15:24 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "18/04/05 09:15:24 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "18/04/05 09:15:24 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:24 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:24 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:24 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:24 INFO streaming.PipeMapRed: Records R/W=2158/1\n",
      "18/04/05 09:15:25 INFO streaming.PipeMapRed: R/W/S=10000/8874/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:25 INFO mapreduce.Job: Job job_local810022510_0001 running in uber mode : false\n",
      "18/04/05 09:15:25 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "18/04/05 09:15:26 INFO streaming.PipeMapRed: R/W/S=100000/98986/0 in:100000=100000/1 [rec/s] out:98986=98986/1 [rec/s]\n",
      "18/04/05 09:15:27 INFO streaming.PipeMapRed: R/W/S=200000/197973/0 in:100000=200000/2 [rec/s] out:98986=197973/2 [rec/s]\n",
      "18/04/05 09:15:29 INFO streaming.PipeMapRed: R/W/S=300000/299008/0 in:75000=300000/4 [rec/s] out:74752=299008/4 [rec/s]\n",
      "18/04/05 09:15:29 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "18/04/05 09:15:29 INFO streaming.PipeMapRed: mapRedFinished\n",
      "18/04/05 09:15:29 INFO mapred.LocalJobRunner: \n",
      "18/04/05 09:15:29 INFO mapred.MapTask: Starting flush of map output\n",
      "18/04/05 09:15:29 INFO mapred.MapTask: Spilling map output\n",
      "18/04/05 09:15:29 INFO mapred.MapTask: bufstart = 0; bufend = 1829070; bufvoid = 104857600\n",
      "18/04/05 09:15:29 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24995020(99980080); length = 1219377/6553600\n",
      "18/04/05 09:15:29 INFO mapred.MapTask: Finished spill 0\n",
      "18/04/05 09:15:29 INFO mapred.Task: Task:attempt_local810022510_0001_m_000000_0 is done. And is in the process of committing\n",
      "18/04/05 09:15:29 INFO mapred.LocalJobRunner: Records R/W=2158/1\n",
      "18/04/05 09:15:29 INFO mapred.Task: Task 'attempt_local810022510_0001_m_000000_0' done.\n",
      "18/04/05 09:15:30 INFO mapred.Task: Final Counters for attempt_local810022510_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=33563535\n",
      "\t\tFILE: Number of bytes written=2744111\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=304845\n",
      "\t\tMap output records=304845\n",
      "\t\tMap output bytes=1829070\n",
      "\t\tMap output materialized bytes=2438766\n",
      "\t\tInput split bytes=132\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=304845\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "18/04/05 09:15:30 INFO mapred.LocalJobRunner: Finishing task: attempt_local810022510_0001_m_000000_0\n",
      "18/04/05 09:15:30 INFO mapred.LocalJobRunner: Starting task: attempt_local810022510_0001_m_000001_0\n",
      "18/04/05 09:15:30 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/04/05 09:15:30 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/04/05 09:15:30 INFO mapred.MapTask: Processing split: file:/home/hpc/pn69si/mnmda001/git/exercise-2018/data/nasa/NASA_access_log_Jul95:33554432+33554432\n",
      "18/04/05 09:15:30 INFO mapred.MapTask: numReduceTasks: 1\n",
      "18/04/05 09:15:30 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "18/04/05 09:15:30 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "18/04/05 09:15:30 INFO mapred.MapTask: soft limit at 83886080\n",
      "18/04/05 09:15:30 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "18/04/05 09:15:30 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "18/04/05 09:15:30 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "18/04/05 09:15:30 INFO streaming.PipeMapRed: PipeMapRed exec [/home/hpc/pn69si/mnmda001/git/exercise-2018/03_MapReduce/./map_reduce_solution.py, map]\n",
      "18/04/05 09:15:30 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:30 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:30 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:30 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:30 INFO streaming.PipeMapRed: Records R/W=1592/1\n",
      "18/04/05 09:15:30 INFO streaming.PipeMapRed: R/W/S=10000/8874/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:30 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "18/04/05 09:15:31 INFO streaming.PipeMapRed: R/W/S=100000/98304/0 in:100000=100000/1 [rec/s] out:98304=98304/1 [rec/s]\n",
      "18/04/05 09:15:32 INFO streaming.PipeMapRed: R/W/S=200000/197973/0 in:100000=200000/2 [rec/s] out:98986=197973/2 [rec/s]\n",
      "18/04/05 09:15:34 INFO streaming.PipeMapRed: R/W/S=300000/297871/0 in:100000=300000/3 [rec/s] out:99298=297896/3 [rec/s]\n",
      "18/04/05 09:15:34 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "18/04/05 09:15:34 INFO streaming.PipeMapRed: mapRedFinished\n",
      "18/04/05 09:15:34 INFO mapred.LocalJobRunner: \n",
      "18/04/05 09:15:34 INFO mapred.MapTask: Starting flush of map output\n",
      "18/04/05 09:15:34 INFO mapred.MapTask: Spilling map output\n",
      "18/04/05 09:15:34 INFO mapred.MapTask: bufstart = 0; bufend = 1850922; bufvoid = 104857600\n",
      "18/04/05 09:15:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24980452(99921808); length = 1233945/6553600\n",
      "18/04/05 09:15:34 INFO mapreduce.Job:  map 14% reduce 0%\n",
      "18/04/05 09:15:34 INFO mapred.MapTask: Finished spill 0\n",
      "18/04/05 09:15:34 INFO mapred.Task: Task:attempt_local810022510_0001_m_000001_0 is done. And is in the process of committing\n",
      "18/04/05 09:15:34 INFO mapred.LocalJobRunner: Records R/W=1592/1\n",
      "18/04/05 09:15:34 INFO mapred.Task: Task 'attempt_local810022510_0001_m_000001_0' done.\n",
      "18/04/05 09:15:34 INFO mapred.Task: Final Counters for attempt_local810022510_0001_m_000001_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=67123010\n",
      "\t\tFILE: Number of bytes written=5212045\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=308487\n",
      "\t\tMap output records=308487\n",
      "\t\tMap output bytes=1850922\n",
      "\t\tMap output materialized bytes=2467902\n",
      "\t\tInput split bytes=132\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=308487\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "18/04/05 09:15:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local810022510_0001_m_000001_0\n",
      "18/04/05 09:15:34 INFO mapred.LocalJobRunner: Starting task: attempt_local810022510_0001_m_000002_0\n",
      "18/04/05 09:15:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/04/05 09:15:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/04/05 09:15:34 INFO mapred.MapTask: Processing split: file:/home/hpc/pn69si/mnmda001/git/exercise-2018/data/nasa/NASA_access_log_Jul95:67108864+33554432\n",
      "18/04/05 09:15:34 INFO mapred.MapTask: numReduceTasks: 1\n",
      "18/04/05 09:15:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "18/04/05 09:15:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "18/04/05 09:15:34 INFO mapred.MapTask: soft limit at 83886080\n",
      "18/04/05 09:15:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "18/04/05 09:15:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "18/04/05 09:15:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "18/04/05 09:15:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/hpc/pn69si/mnmda001/git/exercise-2018/03_MapReduce/./map_reduce_solution.py, map]\n",
      "18/04/05 09:15:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:34 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:34 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:34 INFO streaming.PipeMapRed: Records R/W=2407/1\n",
      "18/04/05 09:15:35 INFO streaming.PipeMapRed: R/W/S=10000/8874/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:35 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "18/04/05 09:15:36 INFO streaming.PipeMapRed: R/W/S=100000/98304/0 in:100000=100000/1 [rec/s] out:98304=98304/1 [rec/s]\n",
      "18/04/05 09:15:37 INFO streaming.PipeMapRed: R/W/S=200000/197973/0 in:100000=200000/2 [rec/s] out:98986=197973/2 [rec/s]\n",
      "18/04/05 09:15:38 INFO streaming.PipeMapRed: R/W/S=300000/298325/0 in:100000=300000/3 [rec/s] out:99441=298325/3 [rec/s]\n",
      "18/04/05 09:15:38 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "18/04/05 09:15:38 INFO streaming.PipeMapRed: mapRedFinished\n",
      "18/04/05 09:15:38 INFO mapred.LocalJobRunner: \n",
      "18/04/05 09:15:38 INFO mapred.MapTask: Starting flush of map output\n",
      "18/04/05 09:15:38 INFO mapred.MapTask: Spilling map output\n",
      "18/04/05 09:15:38 INFO mapred.MapTask: bufstart = 0; bufend = 1865652; bufvoid = 104857600\n",
      "18/04/05 09:15:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24970632(99882528); length = 1243765/6553600\n",
      "18/04/05 09:15:39 INFO mapred.MapTask: Finished spill 0\n",
      "18/04/05 09:15:39 INFO mapred.Task: Task:attempt_local810022510_0001_m_000002_0 is done. And is in the process of committing\n",
      "18/04/05 09:15:39 INFO mapreduce.Job:  map 29% reduce 0%\n",
      "18/04/05 09:15:39 INFO mapred.LocalJobRunner: Records R/W=2407/1\n",
      "18/04/05 09:15:39 INFO mapred.Task: Task 'attempt_local810022510_0001_m_000002_0' done.\n",
      "18/04/05 09:15:39 INFO mapred.Task: Final Counters for attempt_local810022510_0001_m_000002_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=100682485\n",
      "\t\tFILE: Number of bytes written=7699619\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=310942\n",
      "\t\tMap output records=310942\n",
      "\t\tMap output bytes=1865652\n",
      "\t\tMap output materialized bytes=2487542\n",
      "\t\tInput split bytes=132\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=310942\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "18/04/05 09:15:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local810022510_0001_m_000002_0\n",
      "18/04/05 09:15:39 INFO mapred.LocalJobRunner: Starting task: attempt_local810022510_0001_m_000003_0\n",
      "18/04/05 09:15:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/04/05 09:15:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/04/05 09:15:39 INFO mapred.MapTask: Processing split: file:/home/hpc/pn69si/mnmda001/git/exercise-2018/data/nasa/NASA_access_log_Jul95:100663296+33554432\n",
      "18/04/05 09:15:39 INFO mapred.MapTask: numReduceTasks: 1\n",
      "18/04/05 09:15:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "18/04/05 09:15:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "18/04/05 09:15:39 INFO mapred.MapTask: soft limit at 83886080\n",
      "18/04/05 09:15:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "18/04/05 09:15:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "18/04/05 09:15:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "18/04/05 09:15:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/hpc/pn69si/mnmda001/git/exercise-2018/03_MapReduce/./map_reduce_solution.py, map]\n",
      "18/04/05 09:15:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:39 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:39 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:39 INFO streaming.PipeMapRed: Records R/W=2272/1\n",
      "18/04/05 09:15:39 INFO streaming.PipeMapRed: R/W/S=10000/8192/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:40 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "18/04/05 09:15:41 INFO streaming.PipeMapRed: R/W/S=100000/98986/0 in:100000=100000/1 [rec/s] out:98986=98986/1 [rec/s]\n",
      "18/04/05 09:15:42 INFO streaming.PipeMapRed: R/W/S=200000/198656/0 in:100000=200000/2 [rec/s] out:99328=198656/2 [rec/s]\n",
      "18/04/05 09:15:43 INFO streaming.PipeMapRed: R/W/S=300000/298023/0 in:100000=300000/3 [rec/s] out:99346=298039/3 [rec/s]\n",
      "18/04/05 09:15:43 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "18/04/05 09:15:43 INFO streaming.PipeMapRed: mapRedFinished\n",
      "18/04/05 09:15:43 INFO mapred.LocalJobRunner: \n",
      "18/04/05 09:15:43 INFO mapred.MapTask: Starting flush of map output\n",
      "18/04/05 09:15:43 INFO mapred.MapTask: Spilling map output\n",
      "18/04/05 09:15:43 INFO mapred.MapTask: bufstart = 0; bufend = 1852938; bufvoid = 104857600\n",
      "18/04/05 09:15:43 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24979108(99916432); length = 1235289/6553600\n",
      "18/04/05 09:15:44 INFO mapred.MapTask: Finished spill 0\n",
      "18/04/05 09:15:44 INFO mapred.Task: Task:attempt_local810022510_0001_m_000003_0 is done. And is in the process of committing\n",
      "18/04/05 09:15:44 INFO mapred.LocalJobRunner: Records R/W=2272/1\n",
      "18/04/05 09:15:44 INFO mapred.Task: Task 'attempt_local810022510_0001_m_000003_0' done.\n",
      "18/04/05 09:15:44 INFO mapred.Task: Final Counters for attempt_local810022510_0001_m_000003_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=134241960\n",
      "\t\tFILE: Number of bytes written=10170241\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=308823\n",
      "\t\tMap output records=308823\n",
      "\t\tMap output bytes=1852938\n",
      "\t\tMap output materialized bytes=2470590\n",
      "\t\tInput split bytes=132\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=308823\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=108\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "18/04/05 09:15:44 INFO mapred.LocalJobRunner: Finishing task: attempt_local810022510_0001_m_000003_0\n",
      "18/04/05 09:15:44 INFO mapred.LocalJobRunner: Starting task: attempt_local810022510_0001_m_000004_0\n",
      "18/04/05 09:15:44 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/04/05 09:15:44 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/04/05 09:15:44 INFO mapred.MapTask: Processing split: file:/home/hpc/pn69si/mnmda001/git/exercise-2018/data/nasa/NASA_access_log_Jul95:134217728+33554432\n",
      "18/04/05 09:15:44 INFO mapred.MapTask: numReduceTasks: 1\n",
      "18/04/05 09:15:44 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "18/04/05 09:15:44 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "18/04/05 09:15:44 INFO mapred.MapTask: soft limit at 83886080\n",
      "18/04/05 09:15:44 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "18/04/05 09:15:44 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "18/04/05 09:15:44 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "18/04/05 09:15:44 INFO streaming.PipeMapRed: PipeMapRed exec [/home/hpc/pn69si/mnmda001/git/exercise-2018/03_MapReduce/./map_reduce_solution.py, map]\n",
      "18/04/05 09:15:44 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:44 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:44 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:44 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:44 INFO streaming.PipeMapRed: Records R/W=2450/1\n",
      "18/04/05 09:15:44 INFO streaming.PipeMapRed: R/W/S=10000/8874/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:45 INFO streaming.PipeMapRed: R/W/S=100000/98304/0 in:100000=100000/1 [rec/s] out:98304=98304/1 [rec/s]\n",
      "18/04/05 09:15:47 INFO streaming.PipeMapRed: R/W/S=200000/197973/0 in:100000=200000/2 [rec/s] out:98986=197973/2 [rec/s]\n",
      "18/04/05 09:15:48 INFO streaming.PipeMapRed: R/W/S=300000/298325/0 in:100000=300000/3 [rec/s] out:99441=298325/3 [rec/s]\n",
      "18/04/05 09:15:48 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "18/04/05 09:15:48 INFO streaming.PipeMapRed: mapRedFinished\n",
      "18/04/05 09:15:48 INFO mapred.LocalJobRunner: \n",
      "18/04/05 09:15:48 INFO mapred.MapTask: Starting flush of map output\n",
      "18/04/05 09:15:48 INFO mapred.MapTask: Spilling map output\n",
      "18/04/05 09:15:48 INFO mapred.MapTask: bufstart = 0; bufend = 1866132; bufvoid = 104857600\n",
      "18/04/05 09:15:48 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24970312(99881248); length = 1244085/6553600\n",
      "18/04/05 09:15:49 INFO mapred.MapTask: Finished spill 0\n",
      "18/04/05 09:15:49 INFO mapred.Task: Task:attempt_local810022510_0001_m_000004_0 is done. And is in the process of committing\n",
      "18/04/05 09:15:49 INFO mapred.LocalJobRunner: Records R/W=2450/1\n",
      "18/04/05 09:15:49 INFO mapred.Task: Task 'attempt_local810022510_0001_m_000004_0' done.\n",
      "18/04/05 09:15:49 INFO mapred.Task: Final Counters for attempt_local810022510_0001_m_000004_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=167800923\n",
      "\t\tFILE: Number of bytes written=12658455\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=311022\n",
      "\t\tMap output records=311022\n",
      "\t\tMap output bytes=1866132\n",
      "\t\tMap output materialized bytes=2488182\n",
      "\t\tInput split bytes=132\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=311022\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=147\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "18/04/05 09:15:49 INFO mapred.LocalJobRunner: Finishing task: attempt_local810022510_0001_m_000004_0\n",
      "18/04/05 09:15:49 INFO mapred.LocalJobRunner: Starting task: attempt_local810022510_0001_m_000005_0\n",
      "18/04/05 09:15:49 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/04/05 09:15:49 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/04/05 09:15:49 INFO mapred.MapTask: Processing split: file:/home/hpc/pn69si/mnmda001/git/exercise-2018/data/nasa/NASA_access_log_Jul95:167772160+33554432\n",
      "18/04/05 09:15:49 INFO mapred.MapTask: numReduceTasks: 1\n",
      "18/04/05 09:15:49 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "18/04/05 09:15:49 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "18/04/05 09:15:49 INFO mapred.MapTask: soft limit at 83886080\n",
      "18/04/05 09:15:49 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "18/04/05 09:15:49 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "18/04/05 09:15:49 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "18/04/05 09:15:49 INFO streaming.PipeMapRed: PipeMapRed exec [/home/hpc/pn69si/mnmda001/git/exercise-2018/03_MapReduce/./map_reduce_solution.py, map]\n",
      "18/04/05 09:15:49 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:49 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:49 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:49 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:49 INFO streaming.PipeMapRed: Records R/W=2390/1\n",
      "18/04/05 09:15:49 INFO streaming.PipeMapRed: R/W/S=10000/8874/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:50 INFO streaming.PipeMapRed: R/W/S=100000/97621/0 in:100000=100000/1 [rec/s] out:97621=97621/1 [rec/s]\n",
      "18/04/05 09:15:52 INFO streaming.PipeMapRed: R/W/S=200000/198656/0 in:100000=200000/2 [rec/s] out:99328=198656/2 [rec/s]\n",
      "18/04/05 09:15:53 INFO streaming.PipeMapRed: R/W/S=300000/299008/0 in:100000=300000/3 [rec/s] out:99669=299008/3 [rec/s]\n",
      "18/04/05 09:15:53 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "18/04/05 09:15:53 INFO streaming.PipeMapRed: mapRedFinished\n",
      "18/04/05 09:15:53 INFO mapred.LocalJobRunner: \n",
      "18/04/05 09:15:53 INFO mapred.MapTask: Starting flush of map output\n",
      "18/04/05 09:15:53 INFO mapred.MapTask: Spilling map output\n",
      "18/04/05 09:15:53 INFO mapred.MapTask: bufstart = 0; bufend = 1866492; bufvoid = 104857600\n",
      "18/04/05 09:15:53 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24970072(99880288); length = 1244325/6553600\n",
      "18/04/05 09:15:53 INFO mapreduce.Job:  map 71% reduce 0%\n",
      "18/04/05 09:15:53 INFO mapred.MapTask: Finished spill 0\n",
      "18/04/05 09:15:54 INFO mapred.Task: Task:attempt_local810022510_0001_m_000005_0 is done. And is in the process of committing\n",
      "18/04/05 09:15:54 INFO mapred.LocalJobRunner: Records R/W=2390/1\n",
      "18/04/05 09:15:54 INFO mapred.Task: Task 'attempt_local810022510_0001_m_000005_0' done.\n",
      "18/04/05 09:15:54 INFO mapred.Task: Final Counters for attempt_local810022510_0001_m_000005_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=201359886\n",
      "\t\tFILE: Number of bytes written=15147149\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=311082\n",
      "\t\tMap output records=311082\n",
      "\t\tMap output bytes=1866492\n",
      "\t\tMap output materialized bytes=2488662\n",
      "\t\tInput split bytes=132\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=311082\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=120\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "18/04/05 09:15:54 INFO mapred.LocalJobRunner: Finishing task: attempt_local810022510_0001_m_000005_0\n",
      "18/04/05 09:15:54 INFO mapred.LocalJobRunner: Starting task: attempt_local810022510_0001_m_000006_0\n",
      "18/04/05 09:15:54 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/04/05 09:15:54 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/04/05 09:15:54 INFO mapred.MapTask: Processing split: file:/home/hpc/pn69si/mnmda001/git/exercise-2018/data/nasa/NASA_access_log_Jul95:201326592+3915776\n",
      "18/04/05 09:15:54 INFO mapred.MapTask: numReduceTasks: 1\n",
      "18/04/05 09:15:54 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "18/04/05 09:15:54 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "18/04/05 09:15:54 INFO mapred.MapTask: soft limit at 83886080\n",
      "18/04/05 09:15:54 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "18/04/05 09:15:54 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "18/04/05 09:15:54 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "18/04/05 09:15:54 INFO streaming.PipeMapRed: PipeMapRed exec [/home/hpc/pn69si/mnmda001/git/exercise-2018/03_MapReduce/./map_reduce_solution.py, map]\n",
      "18/04/05 09:15:54 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:54 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:54 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:54 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:54 INFO streaming.PipeMapRed: Records R/W=2431/1\n",
      "18/04/05 09:15:54 INFO streaming.PipeMapRed: R/W/S=10000/8874/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:54 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "18/04/05 09:15:54 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "18/04/05 09:15:54 INFO streaming.PipeMapRed: mapRedFinished\n",
      "18/04/05 09:15:54 INFO mapred.LocalJobRunner: \n",
      "18/04/05 09:15:54 INFO mapred.MapTask: Starting flush of map output\n",
      "18/04/05 09:15:54 INFO mapred.MapTask: Spilling map output\n",
      "18/04/05 09:15:54 INFO mapred.MapTask: bufstart = 0; bufend = 219078; bufvoid = 104857600\n",
      "18/04/05 09:15:54 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26068348(104273392); length = 146049/6553600\n",
      "18/04/05 09:15:54 INFO mapred.MapTask: Finished spill 0\n",
      "18/04/05 09:15:54 INFO mapred.Task: Task:attempt_local810022510_0001_m_000006_0 is done. And is in the process of committing\n",
      "18/04/05 09:15:54 INFO mapred.LocalJobRunner: Records R/W=2431/1\n",
      "18/04/05 09:15:54 INFO mapred.Task: Task 'attempt_local810022510_0001_m_000006_0' done.\n",
      "18/04/05 09:15:54 INFO mapred.Task: Final Counters for attempt_local810022510_0001_m_000006_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=205276097\n",
      "\t\tFILE: Number of bytes written=15439291\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=36514\n",
      "\t\tMap output records=36513\n",
      "\t\tMap output bytes=219078\n",
      "\t\tMap output materialized bytes=292110\n",
      "\t\tInput split bytes=132\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=36513\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=153\n",
      "\t\tTotal committed heap usage (bytes)=499646464\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3915776\n",
      "18/04/05 09:15:54 INFO mapred.LocalJobRunner: Finishing task: attempt_local810022510_0001_m_000006_0\n",
      "18/04/05 09:15:54 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "18/04/05 09:15:54 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "18/04/05 09:15:54 INFO mapred.LocalJobRunner: Starting task: attempt_local810022510_0001_r_000000_0\n",
      "18/04/05 09:15:54 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/04/05 09:15:54 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/04/05 09:15:54 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@452a182b\n",
      "18/04/05 09:15:54 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=349752512, maxSingleShuffleLimit=87438128, mergeThreshold=230836672, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "18/04/05 09:15:55 INFO reduce.EventFetcher: attempt_local810022510_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "18/04/05 09:15:55 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local810022510_0001_m_000005_0 decomp: 2488658 len: 2488662 to MEMORY\n",
      "18/04/05 09:15:55 INFO reduce.InMemoryMapOutput: Read 2488658 bytes from map-output for attempt_local810022510_0001_m_000005_0\n",
      "18/04/05 09:15:55 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2488658, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2488658\n",
      "18/04/05 09:15:55 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local810022510_0001_m_000001_0 decomp: 2467898 len: 2467902 to MEMORY\n",
      "18/04/05 09:15:55 INFO reduce.InMemoryMapOutput: Read 2467898 bytes from map-output for attempt_local810022510_0001_m_000001_0\n",
      "18/04/05 09:15:55 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2467898, inMemoryMapOutputs.size() -> 2, commitMemory -> 2488658, usedMemory ->4956556\n",
      "18/04/05 09:15:55 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local810022510_0001_m_000004_0 decomp: 2488178 len: 2488182 to MEMORY\n",
      "18/04/05 09:15:56 INFO reduce.InMemoryMapOutput: Read 2488178 bytes from map-output for attempt_local810022510_0001_m_000004_0\n",
      "18/04/05 09:15:56 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2488178, inMemoryMapOutputs.size() -> 3, commitMemory -> 4956556, usedMemory ->7444734\n",
      "18/04/05 09:15:56 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local810022510_0001_m_000003_0 decomp: 2470586 len: 2470590 to MEMORY\n",
      "18/04/05 09:15:56 INFO reduce.InMemoryMapOutput: Read 2470586 bytes from map-output for attempt_local810022510_0001_m_000003_0\n",
      "18/04/05 09:15:56 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2470586, inMemoryMapOutputs.size() -> 4, commitMemory -> 7444734, usedMemory ->9915320\n",
      "18/04/05 09:15:56 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local810022510_0001_m_000006_0 decomp: 292106 len: 292110 to MEMORY\n",
      "18/04/05 09:15:56 INFO reduce.InMemoryMapOutput: Read 292106 bytes from map-output for attempt_local810022510_0001_m_000006_0\n",
      "18/04/05 09:15:56 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 292106, inMemoryMapOutputs.size() -> 5, commitMemory -> 9915320, usedMemory ->10207426\n",
      "18/04/05 09:15:56 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local810022510_0001_m_000000_0 decomp: 2438762 len: 2438766 to MEMORY\n",
      "18/04/05 09:15:56 INFO reduce.InMemoryMapOutput: Read 2438762 bytes from map-output for attempt_local810022510_0001_m_000000_0\n",
      "18/04/05 09:15:56 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2438762, inMemoryMapOutputs.size() -> 6, commitMemory -> 10207426, usedMemory ->12646188\n",
      "18/04/05 09:15:56 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local810022510_0001_m_000002_0 decomp: 2487538 len: 2487542 to MEMORY\n",
      "18/04/05 09:15:56 INFO reduce.InMemoryMapOutput: Read 2487538 bytes from map-output for attempt_local810022510_0001_m_000002_0\n",
      "18/04/05 09:15:56 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2487538, inMemoryMapOutputs.size() -> 7, commitMemory -> 12646188, usedMemory ->15133726\n",
      "18/04/05 09:15:56 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "18/04/05 09:15:56 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
      "18/04/05 09:15:56 INFO reduce.MergeManagerImpl: finalMerge called with 7 in-memory map-outputs and 0 on-disk map-outputs\n",
      "18/04/05 09:15:56 INFO mapred.Merger: Merging 7 sorted segments\n",
      "18/04/05 09:15:56 INFO mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 15133684 bytes\n",
      "18/04/05 09:15:59 INFO reduce.MergeManagerImpl: Merged 7 segments, 15133726 bytes to disk to satisfy reduce memory limit\n",
      "18/04/05 09:15:59 INFO reduce.MergeManagerImpl: Merging 1 files, 15133718 bytes from disk\n",
      "18/04/05 09:15:59 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "18/04/05 09:15:59 INFO mapred.Merger: Merging 1 sorted segments\n",
      "18/04/05 09:15:59 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 15133708 bytes\n",
      "18/04/05 09:15:59 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
      "18/04/05 09:15:59 INFO streaming.PipeMapRed: PipeMapRed exec [/home/hpc/pn69si/mnmda001/git/exercise-2018/03_MapReduce/./map_reduce_solution.py, reduce]\n",
      "18/04/05 09:15:59 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "18/04/05 09:15:59 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "18/04/05 09:15:59 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:59 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:59 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:59 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:15:59 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/04/05 09:16:00 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:100000=100000/1 [rec/s] out:0=0/1 [rec/s]\n",
      "18/04/05 09:16:00 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "18/04/05 09:16:01 INFO mapreduce.Job:  map 100% reduce 67%\n",
      "18/04/05 09:16:01 INFO streaming.PipeMapRed: R/W/S=200000/0/0 in:100000=200000/2 [rec/s] out:0=0/2 [rec/s]\n",
      "18/04/05 09:16:02 INFO streaming.PipeMapRed: R/W/S=300000/0/0 in:100000=300000/3 [rec/s] out:0=0/3 [rec/s]\n",
      "18/04/05 09:16:03 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "18/04/05 09:16:04 INFO streaming.PipeMapRed: R/W/S=400000/0/0 in:100000=400000/4 [rec/s] out:0=0/4 [rec/s]\n",
      "18/04/05 09:16:05 INFO streaming.PipeMapRed: R/W/S=500000/0/0 in:100000=500000/5 [rec/s] out:0=0/5 [rec/s]\n",
      "18/04/05 09:16:06 INFO streaming.PipeMapRed: R/W/S=600000/0/0 in:100000=600000/6 [rec/s] out:0=0/6 [rec/s]\n",
      "18/04/05 09:16:06 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "18/04/05 09:16:07 INFO streaming.PipeMapRed: R/W/S=700000/0/0 in:87500=700000/8 [rec/s] out:0=0/8 [rec/s]\n",
      "18/04/05 09:16:08 INFO streaming.PipeMapRed: R/W/S=800000/0/0 in:88888=800000/9 [rec/s] out:0=0/9 [rec/s]\n",
      "18/04/05 09:16:09 INFO streaming.PipeMapRed: R/W/S=900000/0/0 in:90000=900000/10 [rec/s] out:0=0/10 [rec/s]\n",
      "18/04/05 09:16:09 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "18/04/05 09:16:10 INFO streaming.PipeMapRed: R/W/S=1000000/0/0 in:90909=1000000/11 [rec/s] out:0=0/11 [rec/s]\n",
      "18/04/05 09:16:12 INFO streaming.PipeMapRed: R/W/S=1100000/0/0 in:91666=1100000/12 [rec/s] out:0=0/12 [rec/s]\n",
      "18/04/05 09:16:12 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "18/04/05 09:16:13 INFO streaming.PipeMapRed: R/W/S=1200000/0/0 in:92307=1200000/13 [rec/s] out:0=0/13 [rec/s]\n",
      "18/04/05 09:16:14 INFO streaming.PipeMapRed: R/W/S=1300000/0/0 in:86666=1300000/15 [rec/s] out:0=0/15 [rec/s]\n",
      "18/04/05 09:16:15 INFO streaming.PipeMapRed: R/W/S=1400000/0/0 in:87500=1400000/16 [rec/s] out:0=0/16 [rec/s]\n",
      "18/04/05 09:16:15 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "18/04/05 09:16:16 INFO streaming.PipeMapRed: R/W/S=1500000/0/0 in:88235=1500000/17 [rec/s] out:0=0/17 [rec/s]\n",
      "18/04/05 09:16:17 INFO streaming.PipeMapRed: R/W/S=1600000/0/0 in:88888=1600000/18 [rec/s] out:0=0/18 [rec/s]\n",
      "18/04/05 09:16:18 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "18/04/05 09:16:19 INFO streaming.PipeMapRed: R/W/S=1700000/0/0 in:89473=1700000/19 [rec/s] out:0=0/19 [rec/s]\n",
      "18/04/05 09:16:21 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "18/04/05 09:16:22 INFO streaming.PipeMapRed: R/W/S=1800000/0/0 in:78260=1800000/23 [rec/s] out:0=0/23 [rec/s]\n",
      "18/04/05 09:16:22 INFO mapreduce.Job:  map 100% reduce 97%\n",
      "18/04/05 09:16:23 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "18/04/05 09:16:23 INFO streaming.PipeMapRed: Records R/W=1891714/1\n",
      "18/04/05 09:16:23 INFO streaming.PipeMapRed: mapRedFinished\n",
      "18/04/05 09:16:23 INFO mapred.Task: Task:attempt_local810022510_0001_r_000000_0 is done. And is in the process of committing\n",
      "18/04/05 09:16:23 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "18/04/05 09:16:23 INFO mapred.Task: Task attempt_local810022510_0001_r_000000_0 is allowed to commit now\n",
      "18/04/05 09:16:23 INFO output.FileOutputCommitter: Saved output of task 'attempt_local810022510_0001_r_000000_0' to file:/home/hpc/pn69si/mnmda001/git/exercise-2018/03_MapReduce/nasa-out/_temporary/0/task_local810022510_0001_r_000000\n",
      "18/04/05 09:16:23 INFO mapred.LocalJobRunner: Records R/W=1891714/1 > reduce\n",
      "18/04/05 09:16:23 INFO mapred.Task: Task 'attempt_local810022510_0001_r_000000_0' done.\n",
      "18/04/05 09:16:23 INFO mapred.Task: Final Counters for attempt_local810022510_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=235543793\n",
      "\t\tFILE: Number of bytes written=30573091\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=8\n",
      "\t\tReduce shuffle bytes=15133754\n",
      "\t\tReduce input records=1891714\n",
      "\t\tReduce output records=8\n",
      "\t\tSpilled Records=1891714\n",
      "\t\tShuffled Maps =7\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=7\n",
      "\t\tGC time elapsed (ms)=290\n",
      "\t\tTotal committed heap usage (bytes)=508035072\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=82\n",
      "18/04/05 09:16:23 INFO mapred.LocalJobRunner: Finishing task: attempt_local810022510_0001_r_000000_0\n",
      "18/04/05 09:16:23 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "18/04/05 09:16:24 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "18/04/05 09:16:24 INFO mapreduce.Job: Job job_local810022510_0001 completed successfully\n",
      "18/04/05 09:16:24 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1145591689\n",
      "\t\tFILE: Number of bytes written=99644002\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1891715\n",
      "\t\tMap output records=1891714\n",
      "\t\tMap output bytes=11350284\n",
      "\t\tMap output materialized bytes=15133754\n",
      "\t\tInput split bytes=924\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=8\n",
      "\t\tReduce shuffle bytes=15133754\n",
      "\t\tReduce input records=1891714\n",
      "\t\tReduce output records=8\n",
      "\t\tSpilled Records=3783428\n",
      "\t\tShuffled Maps =7\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=7\n",
      "\t\tGC time elapsed (ms)=818\n",
      "\t\tTotal committed heap usage (bytes)=4096786432\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=205266944\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=82\n",
      "18/04/05 09:16:24 INFO streaming.StreamJob: Output directory: nasa-out\n",
      "CPU times: user 3.83 s, sys: 837 ms, total: 4.67 s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!rm -rf nasa-out\n",
    "!hadoop jar ${HADOOP_HOME}/share/hadoop/tools/lib/hadoop-streaming-2.7.5.jar \\\n",
    "             -input `pwd`/../data/nasa/NASA_access_log_Jul95 -output nasa-out \\\n",
    "             -mapper \"map_reduce_solution.py map\" -reducer \"map_reduce_solution.py reduce\"  \\\n",
    "             -file `pwd`/map_reduce_solution.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.3 Run the program Terasort on 1 GB of data - each record that TeraGen generates is 100 Bytes in size:\n",
    "\n",
    "    hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.5.jar teragen <number_of_records> <output_directory>\n",
    "\n",
    "    hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.5.jar terasort <input_directory> <output_directory>\n",
    "\n",
    "Measure the runtime for each step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/04/03 15:02:04 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "18/04/03 15:02:04 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "18/04/03 15:02:05 INFO terasort.TeraSort: Generating 10000000 using 1\n",
      "18/04/03 15:02:05 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "18/04/03 15:02:06 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1151238665_0001\n",
      "18/04/03 15:02:06 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "18/04/03 15:02:06 INFO mapreduce.Job: Running job: job_local1151238665_0001\n",
      "18/04/03 15:02:06 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "18/04/03 15:02:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/04/03 15:02:06 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
      "18/04/03 15:02:07 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "18/04/03 15:02:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1151238665_0001_m_000000_0\n",
      "18/04/03 15:02:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/04/03 15:02:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/04/03 15:02:07 INFO mapred.MapTask: Processing split: org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeInputSplit@3483d762\n",
      "18/04/03 15:02:07 INFO mapreduce.Job: Job job_local1151238665_0001 running in uber mode : false\n",
      "18/04/03 15:02:07 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "18/04/03 15:02:14 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:02:14 INFO mapreduce.Job:  map 19% reduce 0%\n",
      "18/04/03 15:02:17 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:02:17 INFO mapreduce.Job:  map 27% reduce 0%\n",
      "18/04/03 15:02:20 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:02:20 INFO mapreduce.Job:  map 36% reduce 0%\n",
      "18/04/03 15:02:23 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:02:23 INFO mapreduce.Job:  map 44% reduce 0%\n",
      "18/04/03 15:02:26 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:02:26 INFO mapreduce.Job:  map 53% reduce 0%\n",
      "18/04/03 15:02:29 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:02:29 INFO mapreduce.Job:  map 61% reduce 0%\n",
      "18/04/03 15:02:32 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:02:32 INFO mapreduce.Job:  map 69% reduce 0%\n",
      "18/04/03 15:02:35 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:02:35 INFO mapreduce.Job:  map 78% reduce 0%\n",
      "18/04/03 15:02:38 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:02:38 INFO mapreduce.Job:  map 87% reduce 0%\n",
      "18/04/03 15:02:41 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:02:41 INFO mapreduce.Job:  map 95% reduce 0%\n",
      "18/04/03 15:02:43 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:02:44 INFO mapred.LocalJobRunner: map\n",
      "18/04/03 15:02:44 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "18/04/03 15:02:47 INFO mapred.LocalJobRunner: map\n",
      "18/04/03 15:03:15 INFO mapred.Task: Task:attempt_local1151238665_0001_m_000000_0 is done. And is in the process of committing\n",
      "18/04/03 15:03:15 INFO mapred.LocalJobRunner: map\n",
      "18/04/03 15:03:15 INFO mapred.Task: Task attempt_local1151238665_0001_m_000000_0 is allowed to commit now\n",
      "18/04/03 15:03:15 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1151238665_0001_m_000000_0' to file:/home/hpc/pn69si/mnmda001/git/exercise-2018/03_MapReduce/teragen-1GB/_temporary/0/task_local1151238665_0001_m_000000\n",
      "18/04/03 15:03:15 INFO mapred.LocalJobRunner: map\n",
      "18/04/03 15:03:15 INFO mapred.Task: Task 'attempt_local1151238665_0001_m_000000_0' done.\n",
      "18/04/03 15:03:15 INFO mapred.Task: Final Counters for attempt_local1151238665_0001_m_000000_0: Counters: 16\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=295959\n",
      "\t\tFILE: Number of bytes written=1008404949\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10000000\n",
      "\t\tMap output records=10000000\n",
      "\t\tInput split bytes=82\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=1326\n",
      "\t\tTotal committed heap usage (bytes)=522190848\n",
      "\torg.apache.hadoop.examples.terasort.TeraGen$Counters\n",
      "\t\tCHECKSUM=21472776955442690\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1007812508\n",
      "18/04/03 15:03:15 INFO mapred.LocalJobRunner: Finishing task: attempt_local1151238665_0001_m_000000_0\n",
      "18/04/03 15:03:15 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "18/04/03 15:03:16 INFO mapreduce.Job: Job job_local1151238665_0001 completed successfully\n",
      "18/04/03 15:03:16 INFO mapreduce.Job: Counters: 16\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=295959\n",
      "\t\tFILE: Number of bytes written=1008404949\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10000000\n",
      "\t\tMap output records=10000000\n",
      "\t\tInput split bytes=82\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=1326\n",
      "\t\tTotal committed heap usage (bytes)=522190848\n",
      "\torg.apache.hadoop.examples.terasort.TeraGen$Counters\n",
      "\t\tCHECKSUM=21472776955442690\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1007812508\n",
      "CPU times: user 3.6 s, sys: 1.04 s, total: 4.64 s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.5.jar teragen 10000000 teragen-1GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/04/03 15:03:21 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "18/04/03 15:03:21 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "18/04/03 15:03:22 INFO terasort.TeraSort: Generating 10000000 using 1\n",
      "18/04/03 15:03:22 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "18/04/03 15:03:22 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local722040421_0001\n",
      "18/04/03 15:03:23 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "18/04/03 15:03:23 INFO mapreduce.Job: Running job: job_local722040421_0001\n",
      "18/04/03 15:03:23 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "18/04/03 15:03:23 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/04/03 15:03:23 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
      "18/04/03 15:03:23 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "18/04/03 15:03:23 INFO mapred.LocalJobRunner: Starting task: attempt_local722040421_0001_m_000000_0\n",
      "18/04/03 15:03:23 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/04/03 15:03:23 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/04/03 15:03:23 INFO mapred.MapTask: Processing split: org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeInputSplit@295f4e7\n",
      "18/04/03 15:03:24 INFO mapreduce.Job: Job job_local722040421_0001 running in uber mode : false\n",
      "18/04/03 15:03:24 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "18/04/03 15:03:29 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:03:30 INFO mapreduce.Job:  map 16% reduce 0%\n",
      "18/04/03 15:03:32 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:03:33 INFO mapreduce.Job:  map 24% reduce 0%\n",
      "18/04/03 15:03:35 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:03:36 INFO mapreduce.Job:  map 32% reduce 0%\n",
      "18/04/03 15:03:38 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:03:39 INFO mapreduce.Job:  map 40% reduce 0%\n",
      "18/04/03 15:03:41 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:03:42 INFO mapreduce.Job:  map 48% reduce 0%\n",
      "18/04/03 15:03:44 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:03:45 INFO mapreduce.Job:  map 56% reduce 0%\n",
      "18/04/03 15:03:47 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:03:48 INFO mapreduce.Job:  map 65% reduce 0%\n",
      "18/04/03 15:03:50 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:03:51 INFO mapreduce.Job:  map 73% reduce 0%\n",
      "18/04/03 15:03:53 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:03:54 INFO mapreduce.Job:  map 81% reduce 0%\n",
      "18/04/03 15:03:56 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:03:57 INFO mapreduce.Job:  map 89% reduce 0%\n",
      "18/04/03 15:03:59 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:04:00 INFO mapred.LocalJobRunner: map > map\n",
      "18/04/03 15:04:00 INFO mapreduce.Job:  map 98% reduce 0%\n",
      "18/04/03 15:04:02 INFO mapred.LocalJobRunner: map\n",
      "18/04/03 15:04:03 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "18/04/03 15:04:05 INFO mapred.LocalJobRunner: map\n",
      "18/04/03 15:04:08 INFO mapred.Task: Task:attempt_local722040421_0001_m_000000_0 is done. And is in the process of committing\n",
      "18/04/03 15:04:08 INFO mapred.LocalJobRunner: map\n",
      "18/04/03 15:04:08 INFO mapred.Task: Task attempt_local722040421_0001_m_000000_0 is allowed to commit now\n",
      "18/04/03 15:04:08 INFO output.FileOutputCommitter: Saved output of task 'attempt_local722040421_0001_m_000000_0' to file:/home/hpc/pn69si/mnmda001/git/exercise-2018/03_MapReduce/terasort-1GB/_temporary/0/task_local722040421_0001_m_000000\n",
      "18/04/03 15:04:08 INFO mapred.LocalJobRunner: map\n",
      "18/04/03 15:04:08 INFO mapred.Task: Task 'attempt_local722040421_0001_m_000000_0' done.\n",
      "18/04/03 15:04:08 INFO mapred.Task: Final Counters for attempt_local722040421_0001_m_000000_0: Counters: 16\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=295959\n",
      "\t\tFILE: Number of bytes written=1008403393\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10000000\n",
      "\t\tMap output records=10000000\n",
      "\t\tInput split bytes=82\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=1659\n",
      "\t\tTotal committed heap usage (bytes)=522715136\n",
      "\torg.apache.hadoop.examples.terasort.TeraGen$Counters\n",
      "\t\tCHECKSUM=21472776955442690\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1007812508\n",
      "18/04/03 15:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local722040421_0001_m_000000_0\n",
      "18/04/03 15:04:08 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "18/04/03 15:04:09 INFO mapreduce.Job: Job job_local722040421_0001 completed successfully\n",
      "18/04/03 15:04:09 INFO mapreduce.Job: Counters: 16\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=295959\n",
      "\t\tFILE: Number of bytes written=1008403393\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10000000\n",
      "\t\tMap output records=10000000\n",
      "\t\tInput split bytes=82\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=1659\n",
      "\t\tTotal committed heap usage (bytes)=522715136\n",
      "\torg.apache.hadoop.examples.terasort.TeraGen$Counters\n",
      "\t\tCHECKSUM=21472776955442690\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1007812508\n",
      "CPU times: user 2.73 s, sys: 722 ms, total: 3.45 s\n",
      "Wall time: 53.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.5.jar teragen 10000000 terasort-1GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/03/11 22:30:55 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "18/03/11 22:30:55 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "18/03/11 22:30:56 INFO input.FileInputFormat: Total input paths to process : 1\n",
      "Spent 282ms computing base-splits.\n",
      "Spent 15ms computing TeraScheduler splits.\n",
      "18/03/11 22:30:56 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "18/03/11 22:30:56 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1518461612_0001\n",
      "18/03/11 22:30:57 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "18/03/11 22:30:57 INFO mapreduce.Job: Running job: job_local1518461612_0001\n",
      "18/03/11 22:30:57 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "18/03/11 22:30:57 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/03/11 22:30:57 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
      "18/03/11 22:30:57 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "18/03/11 22:30:57 INFO mapred.LocalJobRunner: Starting task: attempt_local1518461612_0001_m_000000_0\n",
      "18/03/11 22:30:57 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/03/11 22:30:57 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/03/11 22:30:57 INFO mapred.MapTask: Processing split: file:/naslx/projects/ug201/di57hah/exercise-2018/03_MapReduce/terasort-1GB/part-m-00000:0+1000000000\n",
      "18/03/11 22:30:57 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "18/03/11 22:30:57 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "18/03/11 22:30:57 INFO mapred.MapTask: soft limit at 83886080\n",
      "18/03/11 22:30:57 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "18/03/11 22:30:57 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "18/03/11 22:30:57 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "18/03/11 22:30:58 INFO mapreduce.Job: Job job_local1518461612_0001 running in uber mode : false\n",
      "18/03/11 22:30:58 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "18/03/11 22:31:03 INFO mapred.LocalJobRunner: map > map\n",
      "18/03/11 22:31:04 INFO mapreduce.Job:  map 6% reduce 0%\n",
      "18/03/11 22:31:06 INFO mapred.LocalJobRunner: map > map\n",
      "18/03/11 22:31:07 INFO mapred.MapTask: Spilling map output\n",
      "18/03/11 22:31:07 INFO mapred.MapTask: bufstart = 0; bufend = 72607305; bufvoid = 104857600\n",
      "18/03/11 22:31:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23394696(93578784); length = 2819701/6553600\n",
      "18/03/11 22:31:07 INFO mapred.MapTask: (EQUATOR) 75450889 kvi 18862716(75450864)\n",
      "18/03/11 22:31:07 INFO mapred.MapTask: Starting flush of map output\n",
      "18/03/11 22:31:07 INFO mapred.MapTask: Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@323dc27\n",
      "java.io.IOException: Spill failed\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.checkSpillException(MapTask.java:1562)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1471)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)\n",
      "\tat org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2019)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:797)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)\n",
      "\tat org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n",
      "\tat java.lang.Thread.run(Thread.java:745)\n",
      "Caused by: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/spill0.out\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:402)\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:150)\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:131)\n",
      "\tat org.apache.hadoop.mapred.MROutputFiles.getSpillFileForWrite(MROutputFiles.java:146)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1592)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.access$900(MapTask.java:876)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer$SpillThread.run(MapTask.java:1532)\n",
      "18/03/11 22:31:07 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "18/03/11 22:31:07 INFO mapreduce.Job:  map 9% reduce 0%\n",
      "18/03/11 22:31:07 WARN mapred.LocalJobRunner: job_local1518461612_0001\n",
      "java.lang.Exception: java.io.IOException: Spill failed\n",
      "\tat org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)\n",
      "\tat org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)\n",
      "Caused by: java.io.IOException: Spill failed\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.checkSpillException(MapTask.java:1562)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1085)\n",
      "\tat org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)\n",
      "\tat org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)\n",
      "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)\n",
      "\tat org.apache.hadoop.examples.terasort.TeraValidate$ValidateMapper.cleanup(TeraValidate.java:105)\n",
      "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:149)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)\n",
      "\tat org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n",
      "\tat java.lang.Thread.run(Thread.java:745)\n",
      "Caused by: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/spill0.out\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:402)\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:150)\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:131)\n",
      "\tat org.apache.hadoop.mapred.MROutputFiles.getSpillFileForWrite(MROutputFiles.java:146)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1592)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.access$900(MapTask.java:876)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer$SpillThread.run(MapTask.java:1532)\n",
      "18/03/11 22:31:08 INFO mapreduce.Job: Job job_local1518461612_0001 failed with state FAILED due to: NA\n",
      "18/03/11 22:31:08 INFO mapreduce.Job: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=132834411\n",
      "\t\tFILE: Number of bytes written=591843\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1315232\n",
      "\t\tMap output records=657113\n",
      "\t\tMap output bytes=67682566\n",
      "\t\tMap output materialized bytes=0\n",
      "\t\tInput split bytes=152\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=1729\n",
      "\t\tTotal committed heap usage (bytes)=522190848\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=132554752\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.5.jar teravalidate terasort-1GB teravalidate-1GB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
